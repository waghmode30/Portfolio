# -*- coding: utf-8 -*-
"""ResNet152v2_precfect_trail_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fKeMZVo7Rw2LL6zvBPTy9GEzH1mzPXGn

# Import necessary libraries
"""

import numpy as np
from keras.datasets import cifar10
from keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation
from keras.optimizers import Adam
from keras.callbacks import ModelCheckpoint
from keras.preprocessing.image import ImageDataGenerator
import matplotlib.pyplot as plt

"""# Load CIFAR-10 dataset and split into training and testing sets"""

(x_train, y_train), (x_test, y_test) = cifar10.load_data()

"""#Create a validation set by randomly selecting 20% of the training images"""

validation_split = 0.2
validation_samples = int(len(x_train) * validation_split)
x_val = x_train[:validation_samples]
y_val = y_train[:validation_samples]
x_train = x_train[validation_samples:]
y_train = y_train[validation_samples:]

"""# Scale pixel values to a range between 0 and 1"""

x_train = x_train.astype('float32') / 255
x_val = x_val.astype('float32') / 255
x_test = x_test.astype('float32') / 255

"""# Convert labels to binary class matrices"""

y_train = to_categorical(y_train, 10)
y_val = to_categorical(y_val, 10)
y_test = to_categorical(y_test, 10)

"""# Import necessary libraries for model creation"""

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers import Dense, Flatten, Activation
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import Adam
from keras.preprocessing.image import ImageDataGenerator
from keras.src.layers.serialization import activation

"""# Build CNN model with data augmentation"""

data_generator = ImageDataGenerator(rotation_range=10, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)
data_generator.fit(x_train)


model_augmented = Sequential()
pretraining_model = tf.keras.applications.ResNet152V2(
    include_top=False,
    weights="imagenet",
    input_tensor=None,
    input_shape=(32, 32, 3),
    pooling=None,  # No global pooling in the pre-trained model
    classes=10
)

for layer in pretraining_model.layers:
    layer.trainable = True

model_augmented.add(pretraining_model)
model_augmented.add(Conv2D(32, (3, 3), activation='relu', padding='same', input_shape=(32, 32, 3)))
model_augmented.add(Activation('relu'))
model_augmented.add(Conv2D(32, (3, 3), activation='relu', padding='same'))
model_augmented.add(Activation('relu'))
model_augmented.add(MaxPooling2D(pool_size=(1, 1)))
model_augmented.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
model_augmented.add(Activation('relu'))
model_augmented.add(Conv2D(64, (3, 3), activation='relu', padding='same'))
model_augmented.add(Activation('relu'))
model_augmented.add(MaxPooling2D(pool_size=(1, 1)))
model_augmented.add(Flatten())
model_augmented.add(Dense(512, activation='relu'))
model_augmented.add(Dropout(0.5))
model_augmented.add(Dense(10, activation='softmax'))

model_augmented.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.001), metrics=['accuracy'])
checkpoint_augmented = ModelCheckpoint('best_model_augmented.h5', save_best_only=True, monitor='val_loss', mode='min', verbose=1)
history_augmented = model_augmented.fit(data_generator.flow(x_train, y_train, batch_size=512), epochs=50, validation_data=(x_val, y_val), callbacks=[checkpoint_augmented])
model_augmented.load_weights('best_model_augmented.h5')
train_loss_augmented, train_accuracy_augmented = model_augmented.evaluate(x_train, y_train)
val_loss_augmented, val_accuracy_augmented = model_augmented.evaluate(x_val, y_val)

"""# Plot: Loss vs Epoch (with data augmentation)"""

plt.figure(figsize=(12, 4))

# Plotting Training and Validation Loss
plt.subplot(1, 2, 1)
plt.plot(history_augmented.history['loss'], label='Training Loss', color='blue', marker='o')
plt.plot(history_augmented.history['val_loss'], label='Validation Loss', color='orange', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Model with Data Augmentation')
plt.legend()
plt.grid(True)
plt.tight_layout()

plt.axhline(0, color='black',linewidth=0.5)
plt.axvline(0, color='black',linewidth=0.5)
plt.title('Training and Validation Loss Over Epochs')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.7)
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.tight_layout()

plt.show()

"""# Plot: Accuracy vs Epoch (with data augmentation)"""

plt.figure(figsize=(12, 4))

# Plotting Training and Validation Accuracy
plt.subplot(1, 2, 2)
plt.plot(history_augmented.history['accuracy'], label='Training Accuracy', color='green', marker='o')
plt.plot(history_augmented.history['val_accuracy'], label='Validation Accuracy', color='red', marker='o')
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.title('Model with Data Augmentation')
plt.legend()
plt.grid(True)

plt.axhline(0, color='black', linewidth=0.5)
plt.axvline(0, color='black', linewidth=0.5)
plt.title('Training and Validation Accuracy Over Epochs')
plt.legend()
plt.grid(True, linestyle='--', alpha=0.7)
plt.xlabel('Epoch')
plt.ylabel('Accuracy (%)')
plt.legend()
plt.tight_layout()

plt.show()

"""# Print training and validation accuracy and loss for the model (with data augmentation)"""

print("\nModel with Data Augmentation:")
print("Training Loss: {:.4f}".format(history_augmented.history['loss'][-1]))
print("Training Accuracy: {:.4f}%".format(history_augmented.history['accuracy'][-1] * 100))
print("Validation Loss: {:.4f}".format(history_augmented.history['val_loss'][-1]))
print("Validation Accuracy: {:.4f}%".format(history_augmented.history['val_accuracy'][-1] * 100))

"""# Print summary of the model (with Data Augmentation)"""

print("\nModel Summary (with Data Augmentation):")
model_augmented.summary()

"""# Evaluate the model with test data"""

test_loss, test_accuracy = model_augmented.evaluate(x_test, y_test)
print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy*100:.2f}%')

"""#Plotting the confusion matrix as heatmap"""

from sklearn.metrics import confusion_matrix, classification_report, accuracy_score

# Predict classes for test set
y_pred = model_augmented.predict(x_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

# Compute confusion matrix
conf_matrix = confusion_matrix(y_true, y_pred_classes)
print("Confusion Matrix:")
print(conf_matrix)

# Compute classification report
class_report = classification_report(y_true, y_pred_classes, target_names=[str(i) for i in range(10)])
print("Classification Report:")
print(class_report)

# Compute accuracy
accuracy = accuracy_score(y_true, y_pred_classes)
print("Accuracy:", accuracy)

"""# Confusion matrix plot"""

import seaborn as sns
import matplotlib.pyplot as plt

# Compute confusion matrix
conf_matrix = confusion_matrix(y_true, y_pred_classes)

# Plot confusion matrix heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues', xticklabels=[str(i) for i in range(10)], yticklabels=[str(i) for i in range(10)])
plt.title('Confusion Matrix')
plt.xlabel('Predicted')
plt.ylabel('True')
plt.show()